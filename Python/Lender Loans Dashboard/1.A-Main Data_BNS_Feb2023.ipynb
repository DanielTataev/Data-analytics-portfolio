{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "766791e0-b633-41e6-a27a-0fbf714790b5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nRequirement already satisfied: openpyxl in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages (3.1.4)\nRequirement already satisfied: et-xmlfile in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages (from openpyxl) (1.1.0)\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "# needed to import excel files\n",
    "%pip install -i https://pypi.org/simple openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d0d8678-e77c-4a9e-a41d-3b3ca1a367c2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta \n",
    "from getpass import getuser as get_user \n",
    "from getpass import getpass as get_password \n",
    "from os import environ as enviroment_vars \n",
    "from os import setpgrp as set_process_group \n",
    "from random import random \n",
    "from shlex import split as cmd_split \n",
    "from string import punctuation \n",
    "from subprocess import Popen, PIPE, STDOUT \n",
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b7240ce-264d-475b-8ebb-d16201880d0f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.245.8.142:40001\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://10.245.8.142:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Databricks Shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f8b5f006500>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import SparkContext, HiveContext, SparkConf  \n",
    "from pyspark.sql import SparkSession \n",
    "\n",
    "ss = SparkSession(sc) \n",
    "ss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc2bcf6e-66de-4092-9c77-d14d7bdb240a",
     "showTitle": false,
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current year end: 2024-08-31 00:00:00\nCurrent year beginning: 2024-01-01 00:00:00\nPrevious year end: 2023-08-31 00:00:00\nPrevious year beginning: 2023-01-01 00:00:00\nREPORT_MNTH_6: 2024-02-29 00:00:00\nREPORT_MNTH_18: 2023-03-01 00:00:00\nPRIOR_YTD_END2: 2022-09-30 00:00:00\nPRIOR_YTD_BEG2: 2021-09-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Create datetime filters for the monthly calculation\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "today = datetime.today()\n",
    "\n",
    "if today.month == 1:\n",
    "    month = 12\n",
    "    year = today.year - 1\n",
    "else:\n",
    "    month = today.month - 1\n",
    "    year = today.year\n",
    "\n",
    "CURRENT_YTD_END = datetime(year, month, 1) + relativedelta(day=31)\n",
    "CURRENT_YTD_BEG = datetime(year, 1, 1)\n",
    "\n",
    "if today.month == 1:\n",
    "    month = 12\n",
    "    year = today.year - 2\n",
    "else:\n",
    "    month = today.month - 1\n",
    "    year = today.year - 1\n",
    "\n",
    "PRIOR_YTD_END = datetime(year, month, 1) + relativedelta(day=31)\n",
    "PRIOR_YTD_BEG = datetime(PRIOR_YTD_END.year, 1, 1)\n",
    "\n",
    "REPORT_MNTH_6 = datetime(today.year, today.month, 29) + relativedelta(months=-7)\n",
    "REPORT_MNTH_18 = datetime(today.year, today.month, 1) + relativedelta(months=-18)\n",
    "REPORT_MNTH_19 = datetime(today.year, today.month, 29) + relativedelta(months=-19)\n",
    "REPORT_MNTH_30 = datetime(today.year, today.month, 1) + relativedelta(months=-30)\n",
    "PRIOR_YTD_END2 = datetime(today.year, today.month, 1) + relativedelta(years=-2, day=31)\n",
    "PRIOR_YTD_BEG2 = datetime(today.year, today.month, 1) + relativedelta(years=-3)\n",
    "\n",
    "# ONLY USE BELOW in Jan each year\n",
    "# CURRENT_YTD_END = datetime(today.year-1, 12, 31) #change date number to last day of the previous month\n",
    "# CURRENT_YTD_BEG = datetime(today.year-1, 1, 1)\n",
    "# PRIOR_YTD_END = datetime(today.year - 2, 12, 31) #change date number to last day of the previous month\n",
    "# PRIOR_YTD_BEG = datetime(PRIOR_YTD_END.year, 1, 1)\n",
    "# REPORT_MNTH_6 = datetime(today.year, today.month, 31) + relativedelta(months=-7)\n",
    "# REPORT_MNTH_18 = datetime(today.year, today.month, 1) + relativedelta(months=-18)\n",
    "# REPORT_MNTH_19 = datetime(today.year, today.month, 31) + relativedelta(months=-19)\n",
    "# REPORT_MNTH_30 = datetime(today.year, today.month, 1) + relativedelta(months=-30)\n",
    "# PRIOR_YTD_END2 = datetime(today.year, today.month, 31) + relativedelta(months=-25) #change date number to last day of the previous month\n",
    "# PRIOR_YTD_BEG2 = datetime(today.year, 1, 1) + relativedelta(months=-36)\n",
    "\n",
    "print(\"Current year end: \" + str(CURRENT_YTD_END))\n",
    "print(\"Current year beginning: \" + str(CURRENT_YTD_BEG))\n",
    "print(\"Previous year end: \" + str(PRIOR_YTD_END))\n",
    "print(\"Previous year beginning: \" + str(PRIOR_YTD_BEG))\n",
    "print(\"REPORT_MNTH_6: \" + str(REPORT_MNTH_6))\n",
    "print(\"REPORT_MNTH_18: \" + str(REPORT_MNTH_18))\n",
    "print(\"PRIOR_YTD_END2: \" + str(PRIOR_YTD_END2))\n",
    "print(\"PRIOR_YTD_BEG2: \" + str(PRIOR_YTD_BEG2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54c68905-2913-47a2-a09c-37ec0ad7d654",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# pulling ecoplus loans\n",
    "eco_plus = spark.sql(\n",
    "    \"\"\" \n",
    "with eco as (\n",
    "SELECT \n",
    "DISTINCt cmhcno,\n",
    "    CASE\n",
    "        WHEN UPPER(rurmktxt) LIKE '%++EP++%' THEN 1\n",
    "        ELSE 0\n",
    "    END AS eco_plus_app_ind,\n",
    "    CASE\n",
    "        WHEN UPPER(rurmktxt) LIKE '%++EPCAN++%' THEN 1\n",
    "        ELSE 0\n",
    "    END AS eco_plus_canc_ind\n",
    "FROM dbenp001.tben_eventlog\n",
    "WHERE (UPPER(rurmktxt) LIKE '%++EP++%'\n",
    "OR UPPER(rurmktxt) LIKE '%++EPCAN++%')\n",
    "AND SUBSTR(apidstmp, 1, 4) >= '2016'\n",
    ")\n",
    "select\n",
    "\n",
    "cmhcno,\n",
    "case when sum(eco_plus_app_ind)>0 then 1 else 0 end as eco_plus_app_ind,\n",
    "case when sum(eco_plus_canc_ind)>0 then 1 else 0 end as eco_plus_canc_ind\n",
    "\n",
    "from eco\n",
    "group by cmhcno;\n",
    "\"\"\"\n",
    ")\n",
    "eco_plus.createOrReplaceTempView(\"eco_plus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4bbfcfca-e0b8-4c9c-956c-8c13dc46c327",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Calculate Loan level Base Data for previous and current YTD\n",
    "# Pull in 2 years HO High Ratio ALL CMHC Purchase and Refinance loans\n",
    "a = {\n",
    "    \"CURRENT_YTD_BEG\": CURRENT_YTD_BEG,\n",
    "    \"CURRENT_YTD_END\": CURRENT_YTD_END,\n",
    "    \"PRIOR_YTD_BEG\": PRIOR_YTD_BEG,\n",
    "    \"PRIOR_YTD_END\": PRIOR_YTD_END,\n",
    "    \"REPORT_MNTH_6\": REPORT_MNTH_6,\n",
    "    \"REPORT_MNTH_18\": REPORT_MNTH_18,\n",
    "    \"PRIOR_YTD_BEG2\": PRIOR_YTD_BEG2,\n",
    "    \"PRIOR_YTD_END2\": PRIOR_YTD_END2,\n",
    "}\n",
    "\n",
    "sql = \"\"\"\n",
    "select distinct\n",
    "    lad.cmhc_loan_account_nbr,\n",
    "    emili.aplcrecd, \n",
    "    emili.aplcapro,\n",
    "    lad.loan_purpose_type_desc_en,\n",
    "    lad.loan_purpose_tcd,\n",
    "Case when emili.ACSUCD = 0 then 'ENTRD'\n",
    "     when emili.ACSUCD = 1 then 'RECEVD'\n",
    "     when emili.ACSUCD = 2  then 'CANCEL'\n",
    "     when emili.ACSUCD = 3 then 'REJECT'\n",
    "     when emili.ACSUCD = 4 then 'REFUSE'\n",
    "     when emili.ACSUCD = 5  then 'WITHDN'\n",
    "     when emili.ACSUCD = 6 then 'APPRVD'\n",
    "     when emili.ACSUCD = 7  then 'ISSUED'\n",
    "     when emili.ACSUCD = 8  then 'RISKED'\n",
    "     when emili.ACSUCD = 9  then 'FINAL'   \n",
    "     else ' ' end AS LOAN_STATUS_EN,\n",
    "case when lad.loan_purpose_tcd in ('1', '4', '7', '8', '9', 'D', '**') then 'Purchase'       \n",
    "     when lad.loan_purpose_tcd in ('2', '3', '5', 'A', 'E') then 'Refinance'\n",
    "     else 'Unknown' end as loan_purpose,\n",
    "    las.property_lending_value_amt AS LENDING_VALUE,\n",
    "    las.loan_insured_amt AS INSUR_AMT,\n",
    "    las.loan_lender_amt AS LOAN_AMT,\n",
    "    emili.ACSUCD,\n",
    "    emili.TOTUTCT as Unit,\n",
    "    lad.low_ratio_mortgage_tcd,\n",
    "\n",
    "\n",
    "\n",
    "CASE WHEN emili.aplcapro is null THEN 'NEVER APPROVED' \n",
    "    ELSE 'EVER APPROVED' END AS EVER_APPROVED,\n",
    "\n",
    "case when las.ever_approved_date_surrkey<>3 then \"Ever_Approved\" else \"Never Aprroved\" end as EVER_APPROVED2, /*Added 31.07.23*/\n",
    "\n",
    "\n",
    "case when ( emili.aplcrecd between '{0}' and '{1}') and (emili.aplcapro between '{0}' and '{1}') \n",
    "    then 1 else 0\n",
    "    end as Approved_YTD,\n",
    "\n",
    "case when ( emili.aplcrecd between '{0}' and '{1}') and ((emili.aplcapro between '{0}' and '{1}') or \n",
    "(las.finalized_date_surrkey between '{0}' and '{1}') or (emili.APLREJDT between '{0}' and '{1}')) \n",
    "THEN 1 ELSE 0\n",
    "END AS RISKED_YTD,\n",
    "\n",
    "case when ( emili.aplcrecd between '{2}' and '{3}') and (emili.aplcapro between '{2}' and '{3}') \n",
    "then 1 else 0\n",
    "end as Approved_PYTD,\n",
    "\n",
    "case when ( emili.aplcrecd between '{2}' and '{3}')and ((emili.aplcapro between '{2}' and '{3}') or \n",
    "(las.finalized_date_surrkey between '{2}' and '{3}') or (emili.APLREJDT between '{2}' and '{3}')) \n",
    "THEN 1 ELSE 0\n",
    "END AS RISKED_PYTD,\n",
    "\n",
    "/*CANCELLATION RATE*/\n",
    "CASE WHEN ( emili.aplcrecd between '{5}' and '{4}') THEN 1 ELSE 0\n",
    "END AS REC_CXL_YTD,\n",
    "\n",
    "CASE WHEN ( emili.aplcrecd between '{5}' and '{4}') AND emili.ACSUCD = 2 \n",
    "THEN 1 ELSE 0\n",
    "END AS CANCELLED_YTD,\n",
    "\n",
    "/* FUNDING RATE sum('main_data CDIH'[finalized])/sum('main_data CDIH'[approved_funded_period] */\n",
    "\n",
    "CASE WHEN emili.ACSUCD = 9 THEN 1 ELSE 0 \n",
    "END AS finalized_loan,\n",
    "\n",
    "CASE\n",
    "        WHEN (las.ever_approved_date_surrkey BETWEEN '{5}' AND '{4}' AND emili.ACSUCD in (9,6,7) AND emili.FPRMRCAM > 50 AND emili.totinsat > 0) THEN 1 ELSE 0\n",
    "    END AS finalized, /* changed to ever approved 23.05.2024 ( changed from emili.aplcapro to risk_f.aplcapro), and into NBW */\n",
    "    \n",
    "emili.FPRMRCAM,\n",
    "las.ever_approved_date_surrkey,\n",
    "\n",
    "case \n",
    "    when (las.ever_approved_date_surrkey between '{5}' and '{4}') then 1 else 0\n",
    "end as approved_funded_period,   /*  changed to ever approved (  changed from emili.aplcapro to risk_f.aplcapro) */\n",
    "\n",
    "CASE WHEN  pad.urban_rural_cde in ('2','91') AND pad.current_metropolitan_major_area_cde IN ('9000') THEN 'RURAL'\n",
    "    ELSE 'URBAN' \n",
    "    END AS urban_rural,\n",
    "\n",
    "emili.FPRMRCDT as Fprem_date_rec,\n",
    "emili.FPRMRCAM as Fprem_amount, \n",
    "\n",
    "CASE WHEN pad.current_stats_canada_province_nm_en IN ('NEWFOUNDLAND AND LABRADOR', 'NEW BRUNSWICK', 'PRINCE EDWARD ISLAND', \n",
    "    'NOVA SCOTIA') THEN 'ATLANTIC' \n",
    "    WHEN pad.current_stats_canada_province_nm_en IN ('ALBERTA', 'MANITOBA', 'SASKATCHEWAN', 'YUKON', 'NUNAVUT', \n",
    "    'NORTHWEST TERRITORIES') THEN 'PRAIRIES' \n",
    "    ELSE pad.current_stats_canada_province_nm_en \n",
    "END AS REGION, \n",
    "pad.current_metropolitan_major_area_nm as met_name, /*ADDEDxxxxxxxxxxxxxxxxxxxxxxxxxxxxx*/\n",
    "CASE \n",
    "    WHEN pad.current_stats_canada_province_nm_en  LIKE 'ONTARIO' AND pad.current_metropolitan_major_area_cde IN ('2270') THEN 'Toronto' \n",
    "    WHEN pad.current_stats_canada_province_nm_en  LIKE 'ONTARIO' AND pad.current_metropolitan_major_area_cde IN ('0120') THEN 'Barrie' \n",
    "    WHEN pad.current_stats_canada_province_nm_en  LIKE 'ONTARIO' AND pad.current_metropolitan_major_area_cde IN ('0125') THEN 'Brantford' \n",
    "    WHEN pad.current_stats_canada_province_nm_en  LIKE 'ONTARIO' AND pad.current_metropolitan_major_area_cde IN ('2000') THEN 'Greater Sudbury' \n",
    "    WHEN pad.current_stats_canada_province_nm_en  LIKE 'ONTARIO' AND pad.current_metropolitan_major_area_cde IN ('0460','4000') THEN 'Guelph' \n",
    "    WHEN pad.current_stats_canada_province_nm_en  LIKE 'ONTARIO' AND pad.current_metropolitan_major_area_cde IN ('0610') THEN 'Hamilton' \n",
    "    WHEN pad.current_stats_canada_province_nm_en  LIKE 'ONTARIO' AND pad.current_metropolitan_major_area_cde IN ('0700') THEN 'Kingston' \n",
    "    WHEN pad.current_stats_canada_province_nm_en  LIKE 'ONTARIO' AND pad.current_metropolitan_major_area_cde IN ('0850') THEN 'Kitchener-Cambridge-Waterloo' \n",
    "    WHEN pad.current_stats_canada_province_nm_en  LIKE 'ONTARIO' AND pad.current_metropolitan_major_area_cde IN ('0950') THEN 'London' \n",
    "    WHEN pad.current_stats_canada_province_nm_en  LIKE 'ONTARIO' AND pad.current_metropolitan_major_area_cde IN ('1250') THEN 'Oshawa' \n",
    "    WHEN pad.current_stats_canada_province_nm_en  LIKE 'ONTARIO' AND pad.current_metropolitan_major_area_cde IN ('1320','4850') THEN 'Peterborough' \n",
    "    WHEN pad.current_stats_canada_province_nm_en  LIKE 'ONTARIO' AND pad.current_metropolitan_major_area_cde IN ('1160') THEN 'St. Catharines-Niagara' \n",
    "    WHEN pad.current_stats_canada_province_nm_en  LIKE 'ONTARIO' AND pad.current_metropolitan_major_area_cde IN ('2240') THEN 'Oshawa' \n",
    "    WHEN pad.current_stats_canada_province_nm_en  LIKE 'ONTARIO' AND pad.current_metropolitan_major_area_cde IN ('2270') THEN 'Oshawa' \n",
    "    WHEN pad.current_stats_canada_province_nm_en  LIKE 'ONTARIO' AND pad.current_metropolitan_major_area_cde IN ('2640') THEN 'Oshawa' \n",
    "    WHEN pad.current_stats_canada_province_nm_en  LIKE 'ONTARIO' AND pad.current_metropolitan_major_area_cde IN ('1265') THEN 'Ottawa' \n",
    "    WHEN pad.current_stats_canada_province_nm_en  LIKE 'QUEBEC' AND pad.current_metropolitan_major_area_cde IN ('1264') THEN 'Gatineau' \n",
    "    WHEN pad.current_stats_canada_province_nm_en LIKE 'ALBERTA' AND pad.current_metropolitan_major_area_cde LIKE '0140' THEN 'Calgary' \n",
    "    WHEN pad.current_stats_canada_province_nm_en LIKE 'ALBERTA' AND pad.current_metropolitan_major_area_cde LIKE '0340' THEN 'Edmonton' \n",
    "    WHEN pad.current_stats_canada_province_nm_en LIKE 'BRITISH COLUMBIA' AND pad.current_metropolitan_major_area_cde LIKE '2410' THEN 'Vancouver'\n",
    "    WHEN pad.current_stats_canada_province_nm_en LIKE 'BRITISH COLUMBIA' AND pad.current_metropolitan_major_area_cde LIKE '0110' THEN 'Abbotsford-Mission'\n",
    "    WHEN pad.current_stats_canada_province_nm_en LIKE 'BRITISH COLUMBIA' AND pad.current_metropolitan_major_area_cde LIKE '4240' THEN 'Kelowna'\n",
    "    WHEN pad.current_stats_canada_province_nm_en LIKE 'BRITISH COLUMBIA' AND pad.current_metropolitan_major_area_cde LIKE '2440' THEN 'Victoria'\n",
    "    WHEN pad.current_stats_canada_province_nm_en LIKE 'MANITOBA' AND pad.current_metropolitan_major_area_cde LIKE '2680' THEN 'Winnipeg'\n",
    "    WHEN pad.current_stats_canada_province_nm_en LIKE 'NEW BRUNSWICK' AND pad.current_metropolitan_major_area_cde LIKE '4400' THEN 'Moncton'\n",
    "    WHEN pad.current_stats_canada_province_nm_en LIKE 'NEW BRUNSWICK' AND pad.current_metropolitan_major_area_cde LIKE '1600' THEN 'Saint John'\n",
    "    WHEN pad.current_stats_canada_province_nm_en LIKE 'Newfoundland and Labrador' AND pad.current_metropolitan_major_area_cde LIKE '1640' THEN 'St. Johns'\n",
    "    WHEN pad.current_stats_canada_province_nm_en LIKE 'Nova Scotia' AND pad.current_metropolitan_major_area_cde LIKE '0580' THEN 'Halifax'\n",
    "    WHEN pad.current_stats_canada_province_nm_en LIKE 'Saskatchewan' AND pad.current_metropolitan_major_area_cde LIKE '1490' THEN 'Regina'\n",
    "    WHEN pad.current_stats_canada_province_nm_en LIKE 'Saskatchewan' AND pad.current_metropolitan_major_area_cde LIKE '1700' THEN 'Saskatoon'\n",
    "    WHEN pad.current_stats_canada_province_nm_en LIKE 'QUEBEC' AND pad.current_metropolitan_major_area_cde LIKE '1060' THEN 'Montreal'\n",
    "    WHEN pad.current_stats_canada_province_nm_en LIKE 'QUEBEC' AND pad.current_metropolitan_major_area_cde LIKE '1400' THEN 'Quebec' \n",
    "    WHEN pad.current_stats_canada_province_nm_en LIKE 'QUEBEC' AND pad.current_metropolitan_major_area_cde LIKE '0180' THEN 'Saguenay' \n",
    "    WHEN pad.current_stats_canada_province_nm_en LIKE 'QUEBEC' AND pad.current_metropolitan_major_area_cde LIKE '1800' THEN 'Sherbrooke' \n",
    "    WHEN pad.current_stats_canada_province_nm_en LIKE 'QUEBEC' AND pad.current_metropolitan_major_area_cde LIKE '2320' THEN 'Trois-Rivieres' \n",
    "    WHEN pad.urban_rural_cde in ('2','91') AND pad.current_metropolitan_major_area_cde = '9000' THEN 'Rural'\n",
    "    else 'Urban-Other CMA' \n",
    "    end as CMA_URRUR,\n",
    "\n",
    "pad.current_stats_canada_division_cde,\n",
    "pad.current_stats_canada_subdivision_cde,\n",
    "pad.current_metropolitan_major_area_cde,\n",
    "\n",
    "CASE WHEN pad.dwelling_tcd IN ('008','003','018') THEN 'PLEXES' \n",
    "    WHEN pad.dwelling_tcd IN ('005') THEN 'APPART.' \n",
    "    WHEN pad.dwelling_tcd IN ('002','010','004') THEN 'SEMI-DETACHED/STACKED/ROW' \n",
    "    WHEN pad.dwelling_tcd IN ('006') THEN 'MOBILE' \n",
    "    WHEN pad.dwelling_tcd IN ('017') THEN 'MODULAR' \n",
    "    when pad.dwelling_tcd IN ('001') THEN 'SINGLE'\n",
    "    ELSE pad.dwelling_tcd\n",
    "    END AS dwelling_cat,\n",
    "\n",
    "emili.aplsincc as aplic_income_course,\n",
    "\n",
    "pad.dwelling_type_desc_en as dwelling_type_name,\n",
    "lad.loan_security_type_desc_en,\n",
    "\n",
    "case\n",
    "    when lad.loan_security_tcd in ('4') then 1 \n",
    "    else 0 end as Ministerial_Guarantee_Ind,\n",
    "lad.loan_security_tcd,\n",
    "lad.interest_tcd,\n",
    "lad.interest_type_desc_en as Interest_Type,\n",
    "\n",
    "/*\n",
    "case\n",
    "    when lad.interest_tcd in ('1') then 'Fixed'\n",
    "    when lad.interest_tcd in ('2') then 'Adjustable'\n",
    "    when lad.interest_tcd in ('3') then 'Buydown'\n",
    "    when lad.interest_tcd in ('4') then 'VRM'\n",
    "    when lad.interest_tcd in ('5') then 'Indexed LK'\n",
    "    when lad.interest_tcd in ('6') then 'Capped VRM'\n",
    "    else '9' end as Interest_Type,\n",
    "  */\n",
    "\n",
    "trim(lad.business_source_identification_desc_en) as BUSINESS_SOURCE_EN,\n",
    "trim(lad.application_source_type_desc_en) as Applic_SOURCE_EN,\n",
    "\n",
    "concat(trim(lad.original_representative_first_nm), ' ', trim(lad.original_representative_last_nm)) as Original_Rep, /*Brench rep*/\n",
    "trim(lad.contact_nm) as Contact_nm, /*lender's RU*/\n",
    "\n",
    "lend.lender_cde as Lender_cde, /*\"ADMLENDR Initiation lender code branch\"*/\n",
    "lend.lender_nm_en as Lender_EN, /*\"Initiation lender en (branch)\"\t*/\n",
    "lend.parent_level1_lender_nm_en, /*\"Initiation Parent level 1 lender no\"*/\n",
    "lend.parent_level1_lender_cde,\n",
    "lend.parent_level2_lender_nm_en, /*\"Initiation Parent level 1 lender no\"*/\n",
    "lend.parent_level2_lender_cde,\n",
    "\n",
    "lad.installment_completion_type_desc_en as progress_advance,\n",
    "   \n",
    "trim(emili.FINTSTNO) as TRANSIT,\n",
    "concat(trim(emili.FININSCD), '-', trim(emili.FINTSTNO)) as financial_transit,\n",
    "concat(trim(emili.FININSCD), trim(emili.FINTSTNO)) as Transit_DESJ,\n",
    "concat(trim(lad.contact_local_telephone_area_cde), trim(lad.contact_local_telephone_nbr)) as LENDER_TEL_NO,\n",
    " \n",
    "emili.GDSRATIO as GDS, \n",
    "emili.TDSRATIO AS TDS, \n",
    "las.loan_to_value_rtio as LTV_RATIO, \n",
    "\n",
    "(emili.TOTINSAT/emili.BRWTOTIN)*100 as LTI,\n",
    "emili.BRWTOTIN as famili_income,\n",
    "\n",
    "\n",
    "case when pad.new_existing_building_tcd = '1' then 'New'\n",
    "    when pad.new_existing_building_tcd  = '2' then 'Existing'\n",
    "    else 'NA'\n",
    "    end as New_Exist, \n",
    "pad.new_existing_building_type_desc_en,\n",
    "\n",
    "concat(trim(emili.TENURECD), '-', trim(pad.tenure_type_desc_en)) as Tenure_EN, \n",
    "concat(trim(pad.dwelling_tcd), '-', trim(pad.dwelling_type_desc_en)) as Dwelling_EN, \n",
    "\n",
    "case \n",
    "    when lad.occupancy_tcd is null then 'No Code'\n",
    "    when lad.occupancy_tcd in ('01') then 'Owner Occupied'\n",
    "    when lad.occupancy_tcd in ('02') then 'Rental/Investment'\n",
    "    else 'N/A'\n",
    "    end as Occupancy_EN,\n",
    "\n",
    "pad.property_address_municipality_nm as PROP_Municipality,\n",
    "emili.GFTEQTIN as Gift_dp,\n",
    "Case when emili.GFTEQTIN = 1 then \"Gifted DP\"\n",
    "    else \"No Gift\" end as Gifted_dp,\n",
    "\n",
    "bor.borrower_age_year_cnt as FBOR_AGE, \n",
    "\n",
    "case when emili.cursstcd in ('02','03') then 'First Time' /*2=RENT, 3= LIVE WITH PARENTS*/ \n",
    "    else 'Repeat' end as HOMEBUYER_TYPE,\n",
    "\n",
    "CASE WHEN emili.GENCRSC2 IS NULL THEN 'Single Borrower' \n",
    "    ELSE 'Multiple Borrowers' \n",
    "    END as single_multiple_borr,\n",
    "\n",
    "bor.non_permanent_resident_ind as FBOR_NON_PERM_RESIDENT_IND,\n",
    "Case when bor.non_permanent_resident_ind = 1 then \"Non-perm resident\"\n",
    "    else \"Perm resident\" end as Perm_resident,\n",
    "\n",
    "pad.current_stats_canada_province_nm_en as PROP_PROV_EN, \n",
    "\n",
    "case\n",
    "    when lad.cmhc_loan_account_nbr is not null then 1 \n",
    "    else 0\n",
    "    end as Loan,\n",
    "\n",
    "case\n",
    "    when lad.business_source_identification_cde not in ('04', '13') then 'BRANCH' \n",
    "    else lad.business_source_identification_cde  \n",
    "    end as Regroup_B_Source,\n",
    "    \n",
    "\n",
    "substr(cast(emili.aplcrecd as string),1,4) as rec_year,\n",
    "substr(cast(emili.aplcrecd as string),5,2) as rec_month,\n",
    "substr(cast(emili.aplcapro as string),1,4) as apr_year,\n",
    "substr(cast(emili.aplcapro as string),5,2) as apr_month\n",
    "\n",
    "/*\n",
    "CASE WHEN month(aplcrecd) < 10 then CONCAT('0', month(aplcrecd))\n",
    "else month(aplcrecd)\n",
    "END AS MREC,\n",
    "CASE WHEN month(aplcapro) < 10 then CONCAT('0', month(aplcapro))\n",
    "else month(aplcapro)\n",
    "END AS MEVER*/\n",
    "\n",
    "FROM cmwdw_insurance.vwdw_loan_account_dim lad\n",
    "\n",
    "\n",
    "Left join cmwdw_insurance.vwdw_loan_account_sum las\n",
    "    ON lad.loan_account_surrkey = las.loan_account_surrkey\n",
    "    \n",
    "Left join cmwdw_insurance.vwdw_property_account_dim pad\n",
    "    on las.property_account_surrkey=pad.property_account_surrkey\n",
    "\n",
    "Left join ds_ins_risk.ins_risk_last emili\n",
    "    on emili.lnacctno = lad.cmhc_loan_account_nbr\n",
    "\n",
    "left join ds_ins_risk.ins_risk_first risk_f\n",
    "    on lad.cmhc_loan_account_nbr = risk_f.lnacctno\n",
    "    \n",
    "Left join cmwdw_insurance.vwdw_borrower_account_basic_dim bor\n",
    "    on las.first_borrower_account_surrkey = bor.borrower_account_surrkey\n",
    "\n",
    "Left join cmwdw_insurance.vwdw_lender_financial_trnst_dim lend\n",
    "    on las.initiation_lender_financial_transit_surrkey = lend.lender_financial_transit_surrkey\n",
    "\n",
    "where ((emili.aplcapro >='20200101') or (emili.aplcrecd >= '20200101' )) /* Should it only be by received date?*/\n",
    "\n",
    "    AND lad.low_ratio_mortgage_tcd not in ('01','02')\n",
    "    /*AND emili.APLMTHCD = '04' removed as not really needed*/\n",
    "        \n",
    "\"\"\"\n",
    "ss = spark\n",
    "df = ss.sql(\n",
    "    sql.format(\n",
    "        a.get(\"CURRENT_YTD_BEG\"),\n",
    "        a.get(\"CURRENT_YTD_END\"),\n",
    "        a.get(\"PRIOR_YTD_BEG\"),\n",
    "        a.get(\"PRIOR_YTD_END\"),\n",
    "        a.get(\"REPORT_MNTH_6\").strftime(\"%Y%m%d\"),\n",
    "        a.get(\"REPORT_MNTH_18\").strftime(\"%Y%m%d\"),\n",
    "        a.get(\"PRIOR_YTD_BEG2\"),\n",
    "        a.get(\"PRIOR_YTD_END2\"),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da110ab0-ee7d-4e6b-a48a-a408ff52c470",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Perform the join operation\n",
    "df = df.join(eco_plus, df.cmhc_loan_account_nbr == eco_plus.cmhcno, \"left\")\n",
    "\n",
    "# Drop the redundant cmhcno column from eco_plus_selected after the join\n",
    "df = df.drop(eco_plus.cmhcno)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "55341b1f-c839-4ff7-9889-127141f21e61",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filter the dataframe to display only rows where eco_plus_app_ind is not null\n",
    "#filtered_df = df.filter(df.eco_plus_app_ind.isNotNull())\n",
    "#display(filtered_df.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "116aefb4-2545-47fe-a6d8-8a0a62dba464",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#checking how many lenders\n",
    "# distinct_count = df.select(\"parent_level1_lender_nm_en\").distinct().count()\n",
    "#print(\"Distinct count:\", distinct_count)\n",
    "\n",
    "#count_rows=df.count()\n",
    "#print(count_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c0d45aa-f3c5-478d-a7f2-2340af985781",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.databricks.io.cache.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10ac2f05-d12a-46a5-854c-6e6511d3a331",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#convert to pandas to apply next step on columns\n",
    "df=df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3a46446-fc60-4a09-9cd3-e920650746e6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#just fyi\n",
    "#df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2c2a298-b387-47d8-a7e3-c89127577d96",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#column1_sum = df['finalized'].sum()\n",
    "#print(column1_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90cf0965-a752-4e40-a8d5-fa8bc7aab4ec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#check for duplicates\n",
    "#duplicates = df.duplicated(subset=['cmhc_loan_account_nbr']).sum()\n",
    "#print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36244033-56c2-46b9-93de-709cdb38238b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Remove specialt charaters from Contact name and Original Rep fields\n",
    "#df.replace({\"Contact_nm\":{\"-\":\"\", \"'\":\"\"}, 'Original_Rep':{\"-\":\"\", \"'\":\"\"}})\n",
    "df['Original_Rep'] = df['Original_Rep'].replace([\"-\", \"'\"], \"\", regex=True).str.upper()\n",
    "df['Contact_nm'] = df['Contact_nm'].replace([\"-\", \"'\",\"FAXEMILI\"], \"\", regex=True).str.upper()\n",
    "#df['Original_Rep'] = df['Original_Rep'].replace(['-', ' '], '', regex=True).str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95530fe5-80a1-4df8-b2d9-7e553c8bf610",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table creation for Loan Level Base Data with Parent lender and CU Region completed at:  2024-09-06 16:48:26.379542\n"
     ]
    }
   ],
   "source": [
    "# Create 6 new columns with different reordered Contact_nm words to match with BNS Name List\n",
    "df[\"Contact_1\"] = (\n",
    "    df[\"Contact_nm\"].astype(str).str.split().str[0].fillna(\"\")\n",
    "    + df[\"Contact_nm\"].astype(str).str.split().str[1].fillna(\"\")\n",
    "    + df[\"Contact_nm\"].astype(str).str.split().str[2].fillna(\"\")\n",
    ")\n",
    "df[\"Contact_2\"] = (\n",
    "    df[\"Contact_nm\"].astype(str).str.split().str[0].fillna(\"\")\n",
    "    + df[\"Contact_nm\"].astype(str).str.split().str[2].fillna(\"\")\n",
    "    + df[\"Contact_nm\"].astype(str).str.split().str[1].fillna(\"\")\n",
    ")\n",
    "df[\"Contact_3\"] = (\n",
    "    df[\"Contact_nm\"].astype(str).str.split().str[1].fillna(\"\")\n",
    "    + df[\"Contact_nm\"].astype(str).str.split().str[0].fillna(\"\")\n",
    "    + df[\"Contact_nm\"].astype(str).str.split().str[2].fillna(\"\")\n",
    ")\n",
    "df[\"Contact_4\"] = (\n",
    "    df[\"Contact_nm\"].astype(str).str.split().str[1].fillna(\"\")\n",
    "    + df[\"Contact_nm\"].astype(str).str.split().str[2].fillna(\"\")\n",
    "    + df[\"Contact_nm\"].astype(str).str.split().str[0].fillna(\"\")\n",
    ")\n",
    "df[\"Contact_5\"] = (\n",
    "    df[\"Contact_nm\"].astype(str).str.split().str[2].fillna(\"\")\n",
    "    + df[\"Contact_nm\"].astype(str).str.split().str[1].fillna(\"\")\n",
    "    + df[\"Contact_nm\"].astype(str).str.split().str[0].fillna(\"\")\n",
    ")\n",
    "df[\"Contact_6\"] = (\n",
    "    df[\"Contact_nm\"].astype(str).str.split().str[2].fillna(\"\")\n",
    "    + df[\"Contact_nm\"].astype(str).str.split().str[0].fillna(\"\")\n",
    "    + df[\"Contact_nm\"].astype(str).str.split().str[1].fillna(\"\")\n",
    ")\n",
    "\n",
    "# Create 6 new columns with different reordered Original_Rep words to match with HFS Name List\n",
    "df[\"Rep_1\"] = (\n",
    "    df[\"Original_Rep\"].astype(str).str.split().str[0].fillna(\"\")\n",
    "    + df[\"Original_Rep\"].astype(str).str.split().str[1].fillna(\"\")\n",
    "    + df[\"Original_Rep\"].astype(str).str.split().str[2].fillna(\"\")\n",
    ")\n",
    "df[\"Rep_2\"] = (\n",
    "    df[\"Original_Rep\"].astype(str).str.split().str[0].fillna(\"\")\n",
    "    + df[\"Original_Rep\"].astype(str).str.split().str[2].fillna(\"\")\n",
    "    + df[\"Original_Rep\"].astype(str).str.split().str[1].fillna(\"\")\n",
    ")\n",
    "df[\"Rep_3\"] = (\n",
    "    df[\"Original_Rep\"].astype(str).str.split().str[1].fillna(\"\")\n",
    "    + df[\"Original_Rep\"].astype(str).str.split().str[0].fillna(\"\")\n",
    "    + df[\"Original_Rep\"].astype(str).str.split().str[2].fillna(\"\")\n",
    ")\n",
    "df[\"Rep_4\"] = (\n",
    "    df[\"Original_Rep\"].astype(str).str.split().str[1].fillna(\"\")\n",
    "    + df[\"Original_Rep\"].astype(str).str.split().str[2].fillna(\"\")\n",
    "    + df[\"Original_Rep\"].astype(str).str.split().str[0].fillna(\"\")\n",
    ")\n",
    "df[\"Rep_5\"] = (\n",
    "    df[\"Original_Rep\"].astype(str).str.split().str[2].fillna(\"\")\n",
    "    + df[\"Original_Rep\"].astype(str).str.split().str[1].fillna(\"\")\n",
    "    + df[\"Original_Rep\"].astype(str).str.split().str[0].fillna(\"\")\n",
    ")\n",
    "df[\"Rep_6\"] = (\n",
    "    df[\"Original_Rep\"].astype(str).str.split().str[2].fillna(\"\")\n",
    "    + df[\"Original_Rep\"].astype(str).str.split().str[0].fillna(\"\")\n",
    "    + df[\"Original_Rep\"].astype(str).str.split().str[1].fillna(\"\")\n",
    ")\n",
    "\n",
    "df_cu_s = ss.createDataFrame(df)\n",
    "df_cu_s.createOrReplaceTempView(\"df_cu_s\")\n",
    "# print(\"Loan Level Base Data with CU Region row count: \", df_cu_s.count())\n",
    "print(\n",
    "    \"Table creation for Loan Level Base Data with Parent lender and CU Region completed at: \",\n",
    "    str(datetime.now()),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6a1f194-dfda-4250-9169-520c72466ca7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#df_cu_s.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9236d24a-ade9-4f33-b833-0c7823b12c91",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read the BNS Name List Excel File and save as dataframe\n",
    "from pyspark.sql.functions import trim\n",
    "import pandas as pd\n",
    "\n",
    "bns = pd.read_excel(\n",
    "    \"BNS Name List Last Update.xlsx\", dtype={\"INACTIVE_DATE_LASTUPDATE\": str}\n",
    ").astype(str)\n",
    "bns[\"LENDER_CHANNEL_LASTUPDATE\"] = bns[\"LENDER_CHANNEL_LASTUPDATE\"].replace(\n",
    "    \" \", \"\", regex=True\n",
    ")\n",
    "# bns['EFFECTIVE_DATE_LASTUPDATE'] = pd.to_datetime(bns['EFFECTIVE_DATE_LASTUPDATE'], yearfirst=True)\n",
    "# bns['INACTIVE_DATE_LASTUPDATE'] = pd.to_datetime(bns['INACTIVE_DATE_LASTUPDATE'], yearfirst=True)\n",
    "df_bns = ss.createDataFrame(bns)\n",
    "df_bns = df_bns.withColumn(\n",
    "    \"LENDER_CHANNEL_LASTUPDATE\", trim(df_bns.LENDER_CHANNEL_LASTUPDATE)\n",
    ")\n",
    "df_bns.createOrReplaceTempView(\"df_bns\")\n",
    "\n",
    "# Read the HFS Name List Excel File and save as dataframe\n",
    "hfs = pd.read_excel(\n",
    "    \"HFS Name List Last Update.xlsx\",\n",
    "    dtype={\"INACTIVE_DATE_LASTUPDATE\": str, \"EFFECTIVE_DATE_LASTUPDATE\": str},\n",
    ").astype(str)\n",
    "# hfs['EFFECTIVE_DATE_LASTUPDATE'] = pd.to_datetime(hfs['EFFECTIVE_DATE_LASTUPDATE'], yearfirst=True)\n",
    "# hfs['INACTIVE_DATE_LASTUPDATE'] = pd.to_datetime(hfs['INACTIVE_DATE_LASTUPDATE'], yearfirst=True)\n",
    "df_hfs = ss.createDataFrame(hfs)\n",
    "df_hfs.createOrReplaceTempView(\"df_hfs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1825588-245c-45b2-a2ac-d96db35519ed",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged with BNS Employee List Dataframe creation completed at:  2024-09-06 16:48:27.474329\n"
     ]
    }
   ],
   "source": [
    "# Merge Base Data with BNS Employee Name List with VP, Sales Manager info\n",
    "sql_a = \"\"\"\n",
    "select\n",
    "t1.*,\n",
    "t2.EMPLOYEENO_LASTUPDATE as RU_EMPLOYEENO, \n",
    "t2.NAME_LASTUPDATE as RU_NAME1, \n",
    "t2.LENDER_CHANNEL_LASTUPDATE as bns_lender_channel, \n",
    "t2.EFFECTIVE_DATE_LASTUPDATE as RU_Effectivedt, \n",
    "t2.INACTIVE_DATE_LASTUPDATE as RU_Inactivedt, \n",
    "t2.REGIONAL_VP_LASTUPDATE as RU_VP, \n",
    "t2.PROVINCE_LASTUPDATE as RU_Province, \n",
    "    \n",
    "case when t2.EMPLOYEENO_LASTUPDATE is null then 0 else 1 \n",
    "  end as bnsnamelistmatch_ind,\n",
    "\n",
    "    \n",
    "CASE\n",
    "WHEN t1.financial_transit IN ('002-01339', '002-13151', '002-27912','002-78386') THEN 'MOSE'\n",
    "WHEN t1.financial_transit IN ('002-85712') THEN\n",
    "                  CASE WHEN business_source_en = 'BROKER' THEN 'MOSE' \n",
    "                       WHEN business_source_en = 'MORTGAGE SPECIALIST' AND t2.LENDER_CHANNEL_LASTUPDATE = 'MOSE' THEN 'MOSE' \n",
    "                  ELSE 'HFLM' \n",
    "                  END\n",
    "    WHEN t1.financial_transit IN ('002-77966') THEN \n",
    "        CASE WHEN business_source_en = 'MORTGAGE SPECIALIST' THEN 'MOSE'\n",
    "             WHEN business_source_en NOT IN ('MORTGAGE SPECIALIST') THEN \n",
    "                 CASE WHEN t2.LENDER_CHANNEL_LASTUPDATE = 'BRM' THEN 'BRM'\n",
    "                 ELSE 'MOSE'\n",
    "                 END\n",
    "        END\n",
    "    WHEN t1.financial_transit NOT IN ('002-77966','002-85712','002-01339', '002-13151', '002-27912','002-78386') THEN 'BRANCH'\n",
    "    END AS lenderchannel\n",
    "    \n",
    "from df_cu_s t1 \n",
    "left join df_bns t2 \n",
    "on \n",
    "((trim(t1.Contact_1) = trim(t2.NAME_LASTUPDATE) or (T2.NAME2_LASTUPDATE IS NOT NULL AND trim(t1.Contact_1) = trim(t2.NAME2_LASTUPDATE)))\n",
    "and (t1.aplcrecd >= t2.effective_date_lastupdate and (t1.aplcrecd < t2.INACTIVE_DATE_LASTUPDATE OR t2.inactive_date_lastupdate is null))\n",
    ") \n",
    "or \n",
    "((trim(t1.Contact_2) = trim(t2.NAME_LASTUPDATE) or (T2.NAME2_LASTUPDATE IS NOT NULL AND trim(t1.Contact_2) = trim(t2.NAME2_LASTUPDATE)))\n",
    "and (t1.aplcrecd >= t2.effective_date_lastupdate and (t1.aplcrecd < t2.INACTIVE_DATE_LASTUPDATE OR t2.inactive_date_lastupdate is null))\n",
    ") \n",
    "or \n",
    "((trim(t1.Contact_3) = trim(t2.NAME_LASTUPDATE) or (T2.NAME2_LASTUPDATE IS NOT NULL AND trim(t1.Contact_3) = trim(t2.NAME2_LASTUPDATE)))\n",
    "and (t1.aplcrecd >= t2.effective_date_lastupdate and (t1.aplcrecd < t2.INACTIVE_DATE_LASTUPDATE OR t2.inactive_date_lastupdate is null))\n",
    ") \n",
    "or \n",
    "((trim(t1.Contact_4) = trim(t2.NAME_LASTUPDATE) or (T2.NAME2_LASTUPDATE IS NOT NULL AND trim(t1.Contact_4) = trim(t2.NAME2_LASTUPDATE)))\n",
    "and (t1.aplcrecd >= t2.effective_date_lastupdate and (t1.aplcrecd < t2.INACTIVE_DATE_LASTUPDATE OR t2.inactive_date_lastupdate is null))\n",
    ") or \n",
    "((trim(t1.Contact_5) = trim(t2.NAME_LASTUPDATE) or (T2.NAME2_LASTUPDATE IS NOT NULL AND trim(t1.Contact_5) = trim(t2.NAME2_LASTUPDATE)))\n",
    "and (t1.aplcrecd >= t2.effective_date_lastupdate and (t1.aplcrecd < t2.INACTIVE_DATE_LASTUPDATE OR t2.inactive_date_lastupdate is null))\n",
    ") or \n",
    "((trim(t1.Contact_6) = trim(t2.NAME_LASTUPDATE) or (T2.NAME2_LASTUPDATE IS NOT NULL AND trim(t1.Contact_6) = trim(t2.NAME2_LASTUPDATE)))\n",
    "and (t1.aplcrecd >= t2.effective_date_lastupdate and (t1.aplcrecd < t2.INACTIVE_DATE_LASTUPDATE OR t2.inactive_date_lastupdate is null))\n",
    ") \n",
    "\"\"\"\n",
    "\n",
    "df_base_bns = ss.sql(sql_a)\n",
    "df_base_bns.createOrReplaceTempView(\"df_base_bns\")\n",
    "# print(\"Merged with BNS Employee List table row count: \", df_base_bns.count())\n",
    "print(\n",
    "    \"Merged with BNS Employee List Dataframe creation completed at: \",\n",
    "    str(datetime.now()),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a77f62e-a528-44e0-acb5-fc44a8615b2a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Fill NULL HFS EFFECTIVE_DATE_LASTUPDATE column with default time\n",
    "df_hfs2 = df_hfs.fillna({'EFFECTIVE_DATE_LASTUPDATE':'1900-01-01 00:00:00'})\n",
    "df_hfs2.createOrReplaceTempView(\"df_hfs2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "350c5a15-2f9a-4403-94f5-ae54d12e48df",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Create Dataframe for HFS VP mapping\n",
    "sql_hfs = \"\"\"\n",
    "select distinct *\n",
    "from df_hfs2 \n",
    "where ROLE_LASTUPDATE = \"SMS\"\n",
    "\"\"\"\n",
    "\n",
    "df_hfs_map = ss.sql(sql_hfs)\n",
    "df_hfs_map.createOrReplaceTempView(\"df_hfs_map\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4757c0df-1db0-4c05-ba88-49ea0c64d86b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged with HFS Employee List Dataframe creation completed at:  2024-09-06 16:48:27.847607\n"
     ]
    }
   ],
   "source": [
    "# Merge Previous Dataframe with HFS home finance sales Employee Name List with VP, Sales Manager info.\n",
    "sql_b = \"\"\"\n",
    "select \n",
    "t1.cmhc_loan_account_nbr,\n",
    "    t2.EMPLOYEENO_LASTUPDATE as HFS_EMPLOYEENO, \n",
    "    t2.NAME_LASTUPDATE as HFS_NAME1, \n",
    "    t2.NAME2_LASTUPDATE as HFS_NAME2,\n",
    "    t2.ROLE_LASTUPDATE as HFS_ROLE, \n",
    "    t2.EFFECTIVE_DATE_LASTUPDATE as HFS_Effectivedt, \n",
    "    t2.INACTIVE_DATE_LASTUPDATE as HFS_Inactivedt, \n",
    "    t2.SUPERVISOR_LASTUPDATE as HFS_Supervisor, \n",
    "    t2.PROVINCE_LASTUPDATE as HFS_Province,  \n",
    "    t2.ROLE_LASTUPDATE, \n",
    "    t3.SUPERVISOR_LASTUPDATE as HFS_VP,\n",
    "    \n",
    "case when t2.NAME_LASTUPDATE is not null then 1 else 0\n",
    "end as hfsnamematch_ind,\n",
    "\n",
    "case when t3.NAME_LASTUPDATE is not null then 1 else 0\n",
    "end as vphfsnamematch_ind\n",
    "\n",
    "from df_cu_s t1\n",
    "left join df_hfs2 t2\n",
    "on\n",
    "((trim(t1.Rep_1) = trim(t2.NAME_LASTUPDATE) or (T2.NAME2_LASTUPDATE IS NOT NULL AND trim(t1.Rep_1) = trim(t2.NAME2_LASTUPDATE)))\n",
    "and (t1.aplcrecd >= t2.effective_date_lastupdate and (t1.aplcrecd < t2.INACTIVE_DATE_LASTUPDATE OR t2.inactive_date_lastupdate is null))\n",
    ") \n",
    "or \n",
    "((trim(t1.Rep_2) = trim(t2.NAME_LASTUPDATE) or (T2.NAME2_LASTUPDATE IS NOT NULL AND trim(t1.Rep_2) = trim(t2.NAME2_LASTUPDATE)))\n",
    "and (t1.aplcrecd >= t2.effective_date_lastupdate and (t1.aplcrecd < t2.INACTIVE_DATE_LASTUPDATE OR t2.inactive_date_lastupdate is null))\n",
    ") \n",
    "or \n",
    "((trim(t1.Rep_3) = trim(t2.NAME_LASTUPDATE) or (T2.NAME2_LASTUPDATE IS NOT NULL AND trim(t1.Rep_3) = trim(t2.NAME2_LASTUPDATE)))\n",
    "and (t1.aplcrecd >= t2.effective_date_lastupdate and (t1.aplcrecd < t2.INACTIVE_DATE_LASTUPDATE OR t2.inactive_date_lastupdate is null))\n",
    ") \n",
    "or \n",
    "((trim(t1.Rep_4) = trim(t2.NAME_LASTUPDATE) or (T2.NAME2_LASTUPDATE IS NOT NULL AND trim(t1.Rep_4) = trim(t2.NAME2_LASTUPDATE)))\n",
    "and (t1.aplcrecd >= t2.effective_date_lastupdate and (t1.aplcrecd < t2.INACTIVE_DATE_LASTUPDATE OR t2.inactive_date_lastupdate is null))\n",
    ") or \n",
    "((trim(t1.Rep_5) = trim(t2.NAME_LASTUPDATE) or (T2.NAME2_LASTUPDATE IS NOT NULL AND trim(t1.Rep_5) = trim(t2.NAME2_LASTUPDATE)))\n",
    "and (t1.aplcrecd >= t2.effective_date_lastupdate and (t1.aplcrecd < t2.INACTIVE_DATE_LASTUPDATE OR t2.inactive_date_lastupdate is null))\n",
    ") or \n",
    "((trim(t1.Rep_6) = trim(t2.NAME_LASTUPDATE) or (T2.NAME2_LASTUPDATE IS NOT NULL AND trim(t1.Rep_6) = trim(t2.NAME2_LASTUPDATE)))\n",
    "and (t1.aplcrecd >= t2.effective_date_lastupdate and (t1.aplcrecd < t2.INACTIVE_DATE_LASTUPDATE OR t2.inactive_date_lastupdate is null))\n",
    ") \n",
    "left join df_hfs_map t3  \n",
    "ON (trim(t2.SUPERVISOR_LASTUPDATE) = trim(t3.NAME_LASTUPDATE) or \n",
    "(trim(T3.NAME2_LASTUPDATE) IS NOT NULL AND trim(t2.SUPERVISOR_LASTUPDATE) = trim(t3.NAME2_LASTUPDATE))) \n",
    "AND\n",
    "(t1.aplcrecd >= t3.effective_date_lastupdate and \n",
    "(t1.aplcrecd < t3.INACTIVE_DATE_LASTUPDATE OR t3.inactive_date_lastupdate is NULL))\n",
    "\"\"\"\n",
    "\n",
    "df_base_hfs = ss.sql(sql_b)\n",
    "df_base_hfs.createOrReplaceTempView(\"df_base_hfs\")\n",
    "# print(\"Merged with HFS Employee List table row count: \", df_base_hfs.count())\n",
    "print(\n",
    "    \"Merged with HFS Employee List Dataframe creation completed at: \",\n",
    "    str(datetime.now()),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0098e86e-be62-4958-bdd3-4e0567d15405",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base table with BNS and HFS Employee List table row count:  430669\nBase Table with BNS and HFS Employee List dataframe creation completed at:  2024-09-06 16:48:32.700052\n"
     ]
    }
   ],
   "source": [
    "#Merge BNS and HFS Name List together\n",
    "sql_c = \"\"\"\n",
    "select t1.*,\n",
    "    t2.HFS_EMPLOYEENO, \n",
    "    t2.HFS_NAME1, \n",
    "    t2.HFS_NAME2,\n",
    "    t2.HFS_ROLE, \n",
    "    t2.HFS_Effectivedt, \n",
    "    t2.HFS_Inactivedt, \n",
    "    t2.HFS_Supervisor, \n",
    "    t2.HFS_Province,  \n",
    "    t2.ROLE_LASTUPDATE as HFS_ROLE_LASTUPDATE, \n",
    "    t2.HFS_VP\n",
    "from df_base_bns t1\n",
    "left join df_base_hfs t2\n",
    "on t1.cmhc_loan_account_nbr = t2.cmhc_loan_account_nbr\n",
    "\"\"\"\n",
    "\n",
    "df_base_all = ss.sql(sql_c)\n",
    "df_base_all.createOrReplaceTempView(\"df_base_all\")\n",
    "print(\"Base table with BNS and HFS Employee List table row count: \", df_base_all.count())\n",
    "print(\"Base Table with BNS and HFS Employee List dataframe creation completed at: \", str(datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87d38d51-490e-488b-82c3-ea17c0ca20d9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Calculate Fiscal Year/Month for receive and ever approve date\n",
    "sql_fs = \"\"\"\n",
    "select distinct \n",
    "cmhc_loan_account_nbr,\n",
    "aplcapro,\n",
    "aplcrecd \n",
    "from df_base_all\n",
    "\"\"\"\n",
    "\n",
    "df_fiscal = ss.sql(sql_fs).toPandas()\n",
    "df_fiscal[\"aplcrecd\"] = pd.to_datetime(df_fiscal[\"aplcrecd\"])\n",
    "df_fiscal[\"aplcapro\"] = pd.to_datetime(df_fiscal[\"aplcapro\"])\n",
    "df_fiscal[\"Rec_fiscal_year\"] = df_fiscal[\"aplcrecd\"].dt.to_period(\"Q-OCT\").dt.qyear\n",
    "df_fiscal[\"Ever_fiscal_year\"] = df_fiscal[\"aplcapro\"].dt.to_period(\"Q-OCT\").dt.qyear\n",
    "\n",
    "# Merge Fiscal Year with Main Data and save table in sandbox\n",
    "df_fiscal_ss = ss.createDataFrame(df_fiscal)\n",
    "df_fiscal_ss.createOrReplaceTempView(\"df_fiscal\")\n",
    "\n",
    "sql_fs2 = \"\"\"\n",
    "select t1.*,\n",
    "t2.Rec_fiscal_year,\n",
    "t2.Ever_fiscal_year\n",
    "from df_base_all t1 \n",
    "left join df_fiscal t2\n",
    "on t1.cmhc_loan_account_nbr = t2.cmhc_loan_account_nbr\n",
    "\"\"\"\n",
    "\n",
    "df_fiscal2 = ss.sql(sql_fs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4bb58421-e54c-4e75-b496-faea7c3d4adb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ss.conf.set(\"spark.sql.legacy.allowCreatingManagedTableUsingNonemptyLocation\",\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed93a6e2-b3bd-4a67-9153-04c22b409c81",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Base Table with Channel, Source, BNS Contact creation completed at:  2024-09-06 16:49:10.541347\n"
     ]
    }
   ],
   "source": [
    "df_fiscal2.write.mode(\"overwrite\").format(\"orc\").saveAsTable(\"sb_rmo_ho_reporting.test_lender_dashboard\")\n",
    "#print(\"Final Base Table with Channel, Source, BNS Contact row count: \", df_fiscal2.count())\n",
    "print(\"Final Base Table with Channel, Source, BNS Contact creation completed at: \", str(datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "596b7eaf-e72e-430e-b016-8ea27bdf0eaf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#distinct_count = df_fiscal2.select(\"parent_level1_lender_nm_en\").distinct().count()\n",
    "#print(\"Distinct count:\", distinct_count)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "1.A-Main Data_BNS_Feb2023",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3.5.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
